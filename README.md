

Project Overview

This project presents an intelligent voice command system that understands spoken user commands and maps them to executable intents (e.g., control volume, music, lights, or language settings).
The system combines speech recognition audio embeddings and text-based features in a unified audioâ€“text fusion pipeline to achieve robust and realistic command understanding.


Project Objective

The main objective of this project is to build a realistic and extensible voice command system that:

* Accepts raw audio input (simulating laptop microphone input)
* Converts speech to text using Whisper ASR
* Detects whether the command is in-domain or out-of-domain
* Predicts the correct intent using fused audio and text representations



Dataset
Fluent Speech Commands Dataset



Future Extensions

Real-time microphone input
Support for additional device commands
Integration with OS-level automation
Multilingual command support
